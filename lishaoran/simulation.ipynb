{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"text/plain":["<module 'ntpath' from 'd:\\\\anaconda3\\\\envs\\\\simu\\\\lib\\\\ntpath.py'>"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","os.path"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Import libraries\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from scipy import linalg as LA\n","from sklearn.datasets import make_sparse_spd_matrix\n","from utils.covest import CovEstWithNetwork\n","from utils.adpt_correlation_threshold import AdptCorrThreshold\n","from importlib import reload\n","from wlpy.gist import heatmap"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["rng = np.random.RandomState(19260817)  # we specify a random seed for replication"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["'''\n","N = 10\n","tau = 0.1\n","'''\n","N = 500\n","tau = 0.8 \n","# '''"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["88484\n","5166\n","{'Number of Assets:': 500, 'Generating Method': 'Randomly generate sparse p.d. matrix', 'Observing threshold:': 0.8}\n"]}],"source":["# S = make_spd_matrix(N, random_state=5)\n","S = make_sparse_spd_matrix(N, random_state = 100) \n","G = (abs(S - np.diag(np.diag(S))) > tau) * 1 # off-diagonal entries, of which |.| > tau\n","\n","param_list = {\n","    'Number of Assets:': N, \n","    'Generating Method': 'Randomly generate sparse p.d. matrix',\n","    'Observing threshold:' : tau,   \n","} \n","# df = pd.DataFrame(param_list) \n","print((~(S == 0)).sum()) # number of non-zero entries\n","print(G.sum()) # number of off-diagonal entries, of which |.| > tau\n","print(param_list)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Same setting as in BL2008 cov regularization\n","# The model is AR(1)\n","# N = 400\n","# rho = 0.7\n","# S = np.zeros(shape=[N, N])\n","# for j in range(0, N):\n","#     S = S + np.diag(np.ones(N-j)*(rho**j), -j) + \\\n","#         np.diag(np.ones(N-j)*(rho**j), j)\n","# G = (S >= 0.49) * 1"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["array([[1.    , 0.8   , 0.64  , 0.512 , 0.4096],\n","       [0.8   , 1.    , 0.8   , 0.64  , 0.512 ],\n","       [0.64  , 0.8   , 1.    , 0.8   , 0.64  ],\n","       [0.512 , 0.64  , 0.8   , 1.    , 0.8   ],\n","       [0.4096, 0.512 , 0.64  , 0.8   , 1.    ]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# AR(1)\n","def gen_S(rho = 0.8,N = 500):\n","    S_block = np.zeros(shape=[N, N])\n","    for j in range(0, N):\n","        S_block = S_block + np.diag(np.ones(N-j)*(rho**j), -j) + \\\n","        np.diag(np.ones(N-j)*(rho**j), j)\n","    S = S_block - np.eye(N)\n","    return S\n","\n","S = gen_S(rho=0.8, N=500)\n","S[0:5, 0:5]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.         0.92841126 0.58898673 0.62281627 0.48375082]\n"," [0.92841126 0.         0.83896895 0.57805038 0.20554933]\n"," [0.58898673 0.83896895 0.         0.56399136 0.64265429]\n"," [0.62281627 0.57805038 0.56399136 0.         0.74234067]\n"," [0.48375082 0.20554933 0.64265429 0.74234067 0.        ]]\n","1.165907438691144\n"]}],"source":["'''\n","G: \n","    off-diag = S + noise\n","    diag = 0\n","''' \n","def gen_G(S, scale):\n","    rng = np.random.RandomState(103)\n","    N = S.shape[0]\n","    G = rng.normal(S.reshape(-1), scale = scale).reshape(N, N) # scale: standard deviation of noise\n","    G= 0.5 * (G + G.transpose())\n","    G = G - np.diag(np.diag(G))\n","    return G\n","\n","G = gen_G(S, 0.2)\n","print(G[0:5, 0:5])\n","print(G.max())"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0, 1, 0, 0, 0],\n","       [1, 0, 1, 0, 0],\n","       [0, 1, 0, 1, 0],\n","       [0, 0, 1, 0, 1],\n","       [0, 0, 0, 1, 0]])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# G2: G's big entries\n","def gen_G2(S, tau):\n","    G2 = ((S - np.diag(np.diag(S))) > tau) * 1\n","    return G2\n","G2 = gen_G2(S, tau=0.7)\n","G2[0:5, 0:5]"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["array([[ 0.85562752,  0.85271085, -1.10093045, -1.38497397, -0.06303737],\n","       [-2.69609797, -2.49696008, -2.69361054, -3.01477429, -1.33323753],\n","       [-0.91323525, -1.12412896, -1.10301585, -0.31873741, -0.51136806],\n","       [-1.04047859, -0.70663271, -1.27260778, -1.51379285, -0.28734216],\n","       [ 0.54281987,  0.65436482,  0.44288667, -0.29582842,  0.19589774]])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["def generate_sample(S, T = 200, is_random = False):\n","    if is_random:\n","        rng = np.random\n","    else:\n","        rng = np.random.RandomState(100)\n","    N = S.shape[0]\n","    X1 = rng.multivariate_normal(mean = np.zeros(N), cov = S, size = T)\n","    return X1\n","X1 = generate_sample(S, 200)\n","X1[0:5, 0:5]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def estimate(G, X1):\n","    m = AdptCorrThreshold(pd.DataFrame(X1), G)\n","    b = m.find_smallest_threshold_for_pd()\n","    params = m.params_by_cv('pd', b)\n","    S_new = m.fit_adaptive_corr_threshold(params)   \n","    return m, S_new, params\n","m, S_new, params = estimate(G, X1)\n","print(S_new[0:5, 0:5])\n","print(params) \n","'''\n","When the parameters are default, the threshold\n","tau_ij = (params[0] + params[1] * G_ij) * scaling_factor\n","''' "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["find_smallest_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# without cross-validation\n","S1 = m.fit_adaptive_corr_threshold(params = [2,0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def dd_rslt(S, m, norm_type = 'fro'):\n","    dd = {\"S\": LA.norm(S, ord=norm_type),\n","        \"Sample Cov\": LA.norm(m.sample_cov() - S, ord=norm_type),\n","        \"Linear Shrinkage\": LA.norm(m.lw_lin_shrink() - S, ord=norm_type),\n","        \"Nonlinear Shrinkage\": LA.norm(m.nonlin_shrink() - S, ord=norm_type)}\n","    return dd"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def print_rslt(norm_type='fro'):\n","    print('Norm', norm_type)\n","    print('true', LA.norm(S, ord=norm_type))\n","    print('sample_cov', LA.norm(m.sample_cov() - S, ord=norm_type))\n","    print('lin_shrk', LA.norm(m.lw_lin_shrink() - S, ord=norm_type))\n","    print('nonlin', LA.norm(m.nonlin_shrink() - S, ord=norm_type))\n","    # print(LA.norm(m.ha - S, ord=norm_type))\n","    print('S_new', LA.norm(S_new - S, ord=norm_type))\n","    print('S1', LA.norm(S1 - S, ord=norm_type))\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print_rslt(1)\n","print_rslt(2)\n","print_rslt('fro')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# -> Created on 21 November 2020\n","# -> Author: Weiguang Liu"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["heatmap(S)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["heatmap(S_new)\n","heatmap(S1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["heatmap(m.sample_cov())\n","heatmap(m.lw_lin_shrink())\n","heatmap(m.nonlin_shrink())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["repeat = 2 # 100\n","[estimate(G, generate_sample(S, is_random=True)) for i in range(repeat)]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rslt = []\n","for i in range(1):\n","    for rho in [0.8, 0.9, 0.95, 0.99]:\n","        for scale in np.linspace(0, 0.4, 5):\n","            S = gen_S(rho, N = 500)\n","            G = gen_G(S, scale)\n","            X1 = generate_sample(S, T = 200)\n","            m, S_new, params = estimate(G, X1)\n","            dct = dd_rslt(S, m, 1)\n","            dct[\"Adapt Corr Thresholding\"] = LA.norm(S_new - S, ord=1)\n","            dct[\"rho\"] = rho\n","            dct[\"scale\"] = scale\n","            rslt += [dct]\n","            # print(rho)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rslt2 = []\n","for i in range(1):\n","    for rho in [0.8, 0.9, 0.95, 0.99]:\n","        for l in [0.5, 0.6, 0.7, 0.8, 0.9]:\n","            S = gen_S(rho, N=500)\n","            G2 = gen_G2(S, tau=l)\n","            X1 = generate_sample(S, T=200)\n","            m, S_new, params = estimate(G2, X1)\n","            dct = dd_rslt(S, m, 1)\n","            dct[\"Adapt Corr Thresholding\"] = LA.norm(S_new - S, ord=1)\n","            dct[\"rho\"] = rho\n","            dct[\"l\"] = l\n","            rslt2 += [dct]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.DataFrame(rslt)\n","pd.set_option(\"precision\", 2)\n","df = df.set_index(['rho', 'scale'])\n","with open('rslt.json', 'w') as f:\n","    f.write(df.to_latex())"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 ('simu')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"b1f8481d56ce14143e6478182e374bc2468eaf037e4af344af9b6ae85cf11f37"}}},"nbformat":4,"nbformat_minor":2}
